import numpy as np
import pandas as pd
import os
from tqdm import tqdm  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨
import scipy

# --- 1. Ledoit-Wolf Shrinkage Estimation Function ---


def linear_shrinkage_identity(X, assume_zero_mean=False):

    """
    Ledoit-Wolfç·šå½¢åç¸®æ¨å®šå™¨ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¡Œåˆ—ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸå˜ä½è¡Œåˆ— Iï¼‰ã€‚

    Parameters
    ----------
    X : ndarray, shape (T, N)
        ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—: Tè¦³æ¸¬å€¤ (è¡Œ), Nå¤‰æ•° (åˆ—).
    assume_zero_mean : bool
        Trueã®å ´åˆã€ä¸­å¿ƒåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚Falseã®å ´åˆã€å…±åˆ†æ•£æ¨å®šå‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¸­å¿ƒåŒ–ã™ã‚‹ã€‚

    Returns
    -------
    S : ndarray, shape (N, N)
        æ¨™æœ¬å…±åˆ†æ•£è¡Œåˆ— S.
    Sigma_hat : ndarray, shape (N, N)
        åç¸®å…±åˆ†æ•£è¡Œåˆ— c * mu * I + (1âˆ’c) * S.
    """
    T, N = X.shape

    # ãƒ‡ãƒ¼ã‚¿ã®ä¸­å¿ƒåŒ–
    if not assume_zero_mean:
        X = X - X.mean(axis=0, keepdims=True)

    # æ¨™æœ¬å…±åˆ†æ•£è¡Œåˆ— S
    S = (1.0 / T) * (X.T @ X)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¡Œåˆ—ã®å¹³å‡ mu_hat = (1/N) * Tr(S)
    mu_hat = (1.0 / N) * np.trace(S)

    # delta^2 ã®æ¨å®š: || S âˆ’ mu I ||^2_F
    S_minus = S - mu_hat * np.eye(N)
    delta2_hat = np.sum(S_minus * S_minus)

    # beta^2 ã®æ¨å®š: E|| S âˆ’ Sigma ||^2_F
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ– (ãƒ«ãƒ¼ãƒ—å‡¦ç†ã®æ’é™¤)
    # X_outer: (T, N, N) - å„æ™‚ç‚¹ t ã«ãŠã‘ã‚‹ x_t @ x_t.T
    X_outer = X[:, :, np.newaxis] * X[:, np.newaxis, :]
    diff = X_outer - S
    beta2_hat = np.sum(diff**2) / (T**2)

    # Shrinkage Intensity c_hat ã®è¨ˆç®—
    if delta2_hat <= 0:
        c_hat = 0.0
    else:
        c_hat = beta2_hat / delta2_hat

    c_hat = np.clip(c_hat, 0.0, 1.0)  # 0 <= c_hat <= 1 ã«ã‚¯ãƒªãƒƒãƒ—

    # åç¸®å…±åˆ†æ•£è¡Œåˆ—ã®æ§‹ç¯‰
    Sigma_hat = c_hat * (mu_hat * np.eye(N)) + (1.0 - c_hat) * S

    return S, Sigma_hat


# --- 2. Utility Functions for Portfolio ---


def calculate_mvp_weights(cov_matrix):
    """
    æ¨å®šã•ã‚ŒãŸå…±åˆ†æ•£è¡Œåˆ—ã«åŸºã¥ãã€æœ€å°åˆ†æ•£ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª (MVP) ã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    N = cov_matrix.shape[0]
    ones = np.ones((N, 1))

    # é€†è¡Œåˆ—ã‚’ç”¨ã„ãŸé‡ã¿è¨ˆç®— w = A^-1 * 1 / (1^T * A^-1 * 1)
    # np.linalg.solve ã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–ãƒ»å®‰å®šåŒ– (A * w_tmp = 1 ã‚’è§£ã)
    try:
        w = np.linalg.solve(cov_matrix, ones)
    except np.linalg.LinAlgError:
        # ç‰¹ç•°è¡Œåˆ—ãªã©ã§é€†è¡Œåˆ—ãŒè¨ˆç®—ã§ããªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’é€å‡º
        raise

    # æ­£è¦åŒ– (å’ŒãŒ1ã«ãªã‚‹ã‚ˆã†ã«)
    w = w / w.sum()

    return w.flatten()  # 1æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¿”ã™


def calculate_sharpe_ratio(returns_list):
    """
    ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‹ã‚‰ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ªã‚’è¨ˆç®—ã™ã‚‹ (ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ R_f = 0)ã€‚
    """
    R_p = np.array(returns_list)

    if len(R_p) < 2:
        # è¦³æ¸¬ãŒå°‘ãªã™ãã¦æ¨™æº–åå·®ãŒè¨ˆç®—ã§ããªã„å ´åˆ
        return 0.0

    r_mean = np.mean(R_p)
    # ddof=1: ãƒ™ãƒƒã‚»ãƒ«è£œæ­£ (N-1) ã‚’ç”¨ã„ãŸä¸åæ¨™æº–åå·® (å®Ÿæ¸¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£)
    r_std = np.std(R_p, ddof=1)

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒã‚¼ãƒ­ã®å ´åˆã€Sharpe Ratioã¯è¨ˆç®—ä¸èƒ½
    if r_std == 0:
        return 0.0

    return r_mean / r_std


# --- 3. Data Preparation Function (3æ¬¡ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã«å¤‰æ›´) ---



def prepare_data(input_path, stock_files, start_date, end_date, method="spline"):
    """
    è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šæœŸé–“ã§çµåˆã—ã€æŒ‡å®šã•ã‚ŒãŸæ–¹æ³•ã§æ¬ æå€¤ã‚’è£œé–“ã™ã‚‹ã€‚
    method: 'zero', 'linear', 'spline', 'ffill'
    """
    # æœŸå¾…ã•ã‚Œã‚‹æ—¥ä»˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ (æ¬ æå€¤è£œé–“ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹)
    date_index = pd.to_datetime(pd.date_range(start=start_date, end=end_date, freq="D"))
    data_series_list = []  # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒªãƒ¼ã‚ºã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ

    for file_name in stock_files:
        full_path = os.path.join(input_path, file_name)
        try:
            # å¿…è¦ãªåˆ—ã®ã¿èª­ã¿è¾¼ã¿
            df = pd.read_csv(
                full_path, usecols=["date", "RETX"], dtype={"date": str, "RETX": str}
            )
            df["date"] = pd.to_datetime(df["date"], format="%Y%m%d")
            df.set_index("date", inplace=True)
            
            # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ (åŒæ—¥ã«è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€æœ€å¾Œã‚’æ¡ç”¨)
            if df.index.duplicated().any():
                df = df[~df.index.duplicated(keep='last')]


            # RETXã‚’æ•°å€¤ã«å¤‰æ›ã—ã€å¤‰æ›ã§ããªã„å€¤ã‚’NaNã¨ã™ã‚‹
            df["RETX"] = pd.to_numeric(df["RETX"], errors="coerce")
            stock_name = os.path.splitext(file_name)[0]
            return_series = df["RETX"].rename(stock_name)
            
            # ãƒªã‚¹ãƒˆã«è¿½åŠ 
            data_series_list.append(return_series)

        except Exception as e:
            print(f"è­¦å‘Š: '{file_name}' ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿ: {e}")

    # ä¸€æ‹¬çµåˆ (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š)
    if data_series_list:
        print("-> ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
        master_df = pd.concat(data_series_list, axis=1)
        # æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã®æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã‚‹ (æ¬ ææ—¥ã¯NaNã«ãªã‚‹)
        master_df = master_df.reindex(date_index)
    else:
        print("è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


    # --- ğŸ’¡ æ¬ æå€¤è£œé–“ãƒ­ã‚¸ãƒƒã‚¯ã®å¤‰æ›´ ---
    print(f"-> æ¬ æå€¤è£œé–“ã‚’å®Ÿè¡Œä¸­... (æ‰‹æ³•: {method})")

    try:
        if method == "zero":
            master_df.fillna(0, inplace=True)

        elif method == "linear":
            master_df.interpolate(method="linear", inplace=True)

        elif method == "spline":
            # ãƒ‡ãƒ¼ã‚¿æ•°ãŒæ¥µç«¯ã«å°‘ãªã„å ´åˆã€ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã¯å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
            try:
                master_df.interpolate(method="spline", order=3, inplace=True)
            except Exception as e:
                print(f"è­¦å‘Š: ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã«å¤±æ•— ({e})ã€‚ç·šå½¢è£œé–“ã‚’è©¦ã¿ã¾ã™ã€‚")
                master_df.interpolate(method="linear", inplace=True)

        elif method == "ffill":
            master_df.fillna(method="ffill", inplace=True)

        else:
            print(f"è­¦å‘Š: æœªçŸ¥ã®æ‰‹æ³• '{method}' ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸã€‚ç·šå½¢è£œé–“ã‚’é©ç”¨ã—ã¾ã™ã€‚")
            master_df.interpolate(method="linear", inplace=True)

    except Exception as e:
        print(f"è­¦å‘Š: è£œé–“å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ ({e})ã€‚ã‚¼ãƒ­åŸ‹ã‚ã‚’é©ç”¨ã—ã¾ã™ã€‚")
        master_df.fillna(0, inplace=True)

    # è£œé–“ã§åŸ‹ã‚ãã‚Œãªã‹ã£ãŸæ¬ æå€¤ï¼ˆæ™‚ç³»åˆ—ã®æœ€åˆãªã©ï¼‰ã‚’0ã§è£œé–“
    master_df.fillna(0, inplace=True)

    # æœŸé–“å¤–ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å‰Šé™¤
    master_df = master_df.loc[start_date:end_date]

    # RETXãƒ‡ãƒ¼ã‚¿ (NumPyé…åˆ—)
    retx_data = master_df.to_numpy()
    retx_cols = master_df.columns.tolist()

    print(f"ãƒ‡ãƒ¼ã‚¿çµåˆå®Œäº†ã€‚æœŸé–“: {master_df.index.min()} - {master_df.index.max()}")
    print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {retx_data.shape} ({len(retx_cols)} éŠ˜æŸ„)")

    return retx_data, retx_cols


# --- 4. Main Rolling Window Execution Function ---


def run_backtest(retx_data, train_duration, retx_cols):
    """
    ãƒ­ãƒ¼ãƒ«ãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ»ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ã‚ˆã‚‹ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ªã‚’æ¯”è¼ƒã™ã‚‹ã€‚
    """
    T_total, N = retx_data.shape

    # ã‚¢ã‚¦ãƒˆã‚ªãƒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ»ãƒ†ã‚¹ãƒˆãŒå¯èƒ½ãªæœŸé–“ã®ç·å›æ•°
    num_test_steps = T_total - train_duration

    # ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    r_portfolio_return = []  # æ¨™æœ¬å…±åˆ†æ•£è¡Œåˆ— S ã®ãƒªã‚¿ãƒ¼ãƒ³
    sh_portfolio_return = []  # åç¸®å…±åˆ†æ•£è¡Œåˆ— Sigma_hat ã®ãƒªã‚¿ãƒ¼ãƒ³

    print(f"\n--- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ (T_train={train_duration} / N={N}) ---")
    print(f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {num_test_steps} å›ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ")

    # i: è¨“ç·´æœŸé–“ã®çµ‚äº†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã¤ã¾ã‚Šãƒ†ã‚¹ãƒˆã™ã‚‹ãƒªã‚¿ãƒ¼ãƒ³ã®å‰æ—¥
    for i in tqdm(range(T_total - train_duration), desc="Backtest Progress"):

        # 1. è¨“ç·´æœŸé–“ã®æŠ½å‡º (ãƒ­ãƒ¼ãƒ«ãƒ»ã‚ªãƒ¼ãƒãƒ¼)
        train_retx = retx_data[i : i + train_duration, :]

        # 2. å…±åˆ†æ•£è¡Œåˆ—ã®æ¨å®š
        sample_matrix, shrunken_matrix = linear_shrinkage_identity(train_retx)

        # 3. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé‡ã¿ã®è¨ˆç®—
        # S (æ¨™æœ¬) ã®é‡ã¿
        try:
            w_S = calculate_mvp_weights(sample_matrix)
        except np.linalg.LinAlgError:
            # print(
            #     f"è­¦å‘Š: ã‚¹ãƒ†ãƒƒãƒ— {i} ã§æ¨™æœ¬è¡Œåˆ—ã®é€†è¡Œåˆ—è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é‡ã¿ã‚’ç­‰é…åˆ†(1/N)ã¨ã—ã¾ã™ã€‚"
            # )
            w_S = np.ones(N) / N

        # Sigma_hat (åç¸®) ã®é‡ã¿
        try:
            w_Sh = calculate_mvp_weights(shrunken_matrix)
        except np.linalg.LinAlgError:
            # print(
            #     f"è­¦å‘Š: ã‚¹ãƒ†ãƒƒãƒ— {i} ã§åç¸®è¡Œåˆ—ã®é€†è¡Œåˆ—è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é‡ã¿ã‚’ç­‰é…åˆ†(1/N)ã¨ã—ã¾ã™ã€‚"
            # )
            w_Sh = np.ones(N) / N

        # 4. ã‚¢ã‚¦ãƒˆã‚ªãƒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã®è¨ˆç®—
        test_return = retx_data[i + train_duration, :]

        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ = w^T @ r
        r_s = np.dot(test_return, w_S)
        r_sh = np.dot(test_return, w_Sh)

        # 5. ãƒªã‚¿ãƒ¼ãƒ³ã®è¨˜éŒ²
        r_portfolio_return.append(r_s)
        sh_portfolio_return.append(r_sh)

        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ï¼‰
        if i == 0:
            print(f"  åˆå›ãƒ†ã‚¹ãƒˆæ—¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {i + train_duration}")
            print(f"  æ¨™æœ¬é‡ã¿ (w_S) - æœ€åˆã®5ã¤:\n{w_S[:5]}")
            print(f"  ç¸®å°é‡ã¿ (w_Sh) - æœ€åˆã®5ã¤:\n{w_Sh[:5]}")

    print("\n--- ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ªã®è©•ä¾¡ ---")

    # 6. ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ªã®è¨ˆç®—
    r_sharpe = calculate_sharpe_ratio(r_portfolio_return)
    sh_sharpe = calculate_sharpe_ratio(sh_portfolio_return)

    # 7. å®Ÿæ¸¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®è¨ˆç®—ï¼ˆæ¯”è¼ƒã®ãŸã‚ï¼‰
    r_std = np.std(r_portfolio_return, ddof=1)
    sh_std = np.std(sh_portfolio_return, ddof=1)

    print(
        f"æ¨™æœ¬ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ— (æœ€åˆã®5ã¤): {np.array(r_portfolio_return).flatten()[:5]}"
    )
    print(
        f"åç¸®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ— (æœ€åˆã®5ã¤): {np.array(sh_portfolio_return).flatten()[:5]}"
    )

    print(f"\n--- çµæœæ¯”è¼ƒ ---")
    print(f"æ¨™æœ¬å…±åˆ†æ•£è¡Œåˆ— (S) ã‚’ç”¨ã„ãŸã¨ãã®å®Ÿæ¸¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {r_std:.6f}")
    print(f"åç¸®å…±åˆ†æ•£è¡Œåˆ— (Sigma_hat) ã‚’ç”¨ã„ãŸã¨ãã®å®Ÿæ¸¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {sh_std:.6f}")
    print(f"æ¨™æº–å…±åˆ†æ•£è¡Œåˆ— (S) ã‚’ç”¨ã„ãŸã¨ãã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ª: {r_sharpe:.4f}")
    print(f"ç¸®å°å…±åˆ†æ•£è¡Œåˆ— (Sigma_hat) ã‚’ç”¨ã„ãŸã¨ãã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ»ãƒ¬ã‚·ã‚ª: {sh_sharpe:.4f}")


# --- 5. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ ---

if __name__ == "__main__":
    # 0. è£œé–“æ–¹æ³•ã®è¨­å®š ('zero', 'linear', 'spline', 'ffill')
    INTERPOLATION_METHOD = "linear"

    # 1. ãƒ‘ã‚¹ã®è¨­å®šï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã®å€¤ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
    # ã“ã‚Œã‚‰ã®ãƒ‘ã‚¹ã¯å®Ÿè¡Œç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ãŒå¿…è¦ã§ã™
    input_path = "C:/Users/scarl/Documents/Research/data/input/"

    # 2. å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆ (è‡ªå‹•å–å¾—)
    stock_files = [f for f in os.listdir(input_path) if f.endswith(".csv")]
    
    if not stock_files:
        print(f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ '{input_path}' ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹ã‹ã€ç©ºã®ãƒªã‚¹ãƒˆã®ã¾ã¾é€²ã‚€ã‹ã€‚ã“ã“ã§ã¯ä¸­æ–­ãŒå®‰å…¨ã€‚
        import sys
        sys.exit(1)
        
    print(f"ãƒ•ã‚©ãƒ«ãƒ€ '{input_path}' ã‹ã‚‰ {len(stock_files)} ä»¶ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")


    # 3. æŠ½å‡ºã—ãŸã„æœŸé–“ã¨è¨“ç·´æœŸé–“ã®è¨­å®š
    start_date = "1995-03-01"
    end_date = "2023-12-19"
    train_duration = 21  # T_train (è¨“ç·´æœŸé–“ã®é•·ã•)

    # 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    retx_data, retx_cols = prepare_data(
        input_path, stock_files, start_date, end_date, method=INTERPOLATION_METHOD
    )

    # 5. ãƒ­ãƒ¼ãƒ«ãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ»ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    if retx_data.shape[0] > train_duration and retx_data.shape[1] >= 2:
        run_backtest(retx_data, train_duration, retx_cols)
    else:
        print(
            "\nã‚¨ãƒ©ãƒ¼: è¨“ç·´æœŸé–“ã¾ãŸã¯éŠ˜æŸ„æ•°ãŒä¸ååˆ†ãªãŸã‚ã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚"
        )

